{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9wADwK78DCz"
      },
      "source": [
        "# Proyek Analisis Data: Air-quality-dataset\n",
        "- **Nama:** Arya Setia Pratama\n",
        "- **Email:** aryasetia30@gmail.com\n",
        "- **ID Dicoding:** aryasetia30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE0raob58DC0"
      },
      "source": [
        "## Menentukan Pertanyaan Bisnis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmQeQ5YF8DC0"
      },
      "source": [
        "- Bagaimana tren kualitas udara (PM2.5 dan PM10) di berbagai lokasi dari tahun 2013 hingga 2017?\n",
        "- Faktor meteorologi apa yang paling mempengaruhi konsentrasi polutan di berbagai kota?\n",
        "- Apakah ada perbedaan signifikan dalam kualitas udara antara lokasi yang berbeda pada waktu-waktu tertentu?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-z4QGlO8DC1"
      },
      "source": [
        "## Import Semua Packages/Library yang Digunakan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FVYwaObI8DC1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_Sh51Xy8DC1"
      },
      "source": [
        "## Data Wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXU2GBYu8DC1"
      },
      "source": [
        "### Gathering Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zjCBk1BI8DC1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File CSV berhasil digabungkan dan disimpan ke 'dashboard\\main_data.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Path ke folder tempat file CSV disimpan\n",
        "path = 'data/'  # Sesuaikan dengan path folder kamu\n",
        "\n",
        "# Mengambil semua file CSV yang ada di folder\n",
        "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
        "\n",
        "# List untuk menyimpan DataFrame\n",
        "dataframes = []\n",
        "\n",
        "# Loop untuk memproses setiap file CSV\n",
        "for file in all_files:\n",
        "    try:\n",
        "        # Membaca file CSV\n",
        "        df = pd.read_csv(file)\n",
        "        \n",
        "        # Mendapatkan nama kota dari nama file dengan cara yang lebih fleksibel\n",
        "        # Misalnya, 'PRSA_Data_Gucheng_20130301-20170228.csv' -> 'Gucheng'\n",
        "        city_name = os.path.basename(file).split('_')[2]\n",
        "        \n",
        "        # Menambahkan kolom 'station' dengan nama kota\n",
        "        df['station'] = city_name\n",
        "        \n",
        "        # Menambahkan dataframe ke dalam list\n",
        "        dataframes.append(df)\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"Error membaca file {file}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Menggabungkan semua DataFrame menjadi satu\n",
        "merged_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Memastikan direktori output ada\n",
        "output_dir = 'dashboard'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Menyimpan DataFrame yang sudah digabungkan ke file CSV\n",
        "output_path = os.path.join(output_dir, 'main_data.csv')\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"File CSV berhasil digabungkan dan disimpan ke '{output_path}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMi6xGaDkbCi"
      },
      "source": [
        "**Insight:**\n",
        "- Selama proses penggabungan data dari berbagai file CSV, ditemukan bahwa semua file memiliki struktur kolom yang seragam, yang memudahkan untuk melakukan penggabungan. Setiap file mencakup data dari tahun 2013 hingga 2017 dan berisi kolom yang sama seperti PM2.5, PM10, SO2, NO2, CO, O3, serta data meteorologi seperti suhu dan kelembapan. Konsistensi ini mempercepat proses data wrangling karena tidak perlu penanganan khusus untuk variasi kolom.\n",
        "- Menambahkan kolom station ke dataset untuk menunjukkan lokasi data adalah langkah yang penting. Proses ini memberikan fleksibilitas dalam analisis, karena mempermudah pemisahan dan identifikasi data berdasarkan kota atau lokasi. Dengan adanya kolom ini, tren polusi dapat dengan mudah dianalisis secara geografis, serta memberikan kemampuan untuk membuat visualisasi perbandingan kualitas udara antar kota."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHSiqaZp8DC1"
      },
      "source": [
        "### Assessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ax-3tEjc9Cj1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Missing Values ===\n",
            "PM2.5     8739\n",
            "PM10      6449\n",
            "SO2       9021\n",
            "NO2      12116\n",
            "CO       20701\n",
            "O3       13277\n",
            "TEMP       398\n",
            "PRES       393\n",
            "DEWP       403\n",
            "RAIN       390\n",
            "wd        1822\n",
            "WSPM       318\n",
            "dtype: int64\n",
            "\n",
            "=== Invalid Values ===\n",
            "PM2.5    0\n",
            "PM10     0\n",
            "SO2      0\n",
            "NO2      0\n",
            "CO       0\n",
            "O3       0\n",
            "TEMP     0\n",
            "dtype: int64\n",
            "\n",
            "=== Duplicate Data ===\n",
            "Jumlah baris duplikat: 0\n",
            "\n",
            "=== Outliers ===\n",
            "PM2.5    19142\n",
            "PM10     14658\n",
            "SO2      35566\n",
            "NO2       7021\n",
            "CO       28054\n",
            "O3       16599\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Membaca data yang sudah digabungkan\n",
        "merged_df = pd.read_csv('dashboard/main_data.csv')\n",
        "\n",
        "# 1. Missing Value\n",
        "print(\"=== Missing Values ===\")\n",
        "missing_values = merged_df.isnull().sum()\n",
        "print(missing_values[missing_values > 0])  # Menampilkan kolom yang memiliki missing values\n",
        "\n",
        "# 2. Invalid Value\n",
        "print(\"\\n=== Invalid Values ===\")\n",
        "# Misalnya, kita anggap nilai negatif pada kolom polutan dan temperatur tidak valid\n",
        "invalid_values = {\n",
        "    'PM2.5': merged_df[merged_df['PM2.5'] < 0].shape[0],\n",
        "    'PM10': merged_df[merged_df['PM10'] < 0].shape[0],\n",
        "    'SO2': merged_df[merged_df['SO2'] < 0].shape[0],\n",
        "    'NO2': merged_df[merged_df['NO2'] < 0].shape[0],\n",
        "    'CO': merged_df[merged_df['CO'] < 0].shape[0],\n",
        "    'O3': merged_df[merged_df['O3'] < 0].shape[0],\n",
        "    'TEMP': merged_df[merged_df['TEMP'] < -50].shape[0],  # Misalnya, suhu tidak boleh lebih kecil dari -50 derajat\n",
        "}\n",
        "print(pd.Series(invalid_values))\n",
        "\n",
        "# 3. Duplicate Data\n",
        "print(\"\\n=== Duplicate Data ===\")\n",
        "duplicate_data = merged_df.duplicated().sum()\n",
        "print(f\"Jumlah baris duplikat: {duplicate_data}\")\n",
        "\n",
        "# 4. Outlier\n",
        "print(\"\\n=== Outliers ===\")\n",
        "# Menggunakan metode IQR untuk mendeteksi outliers\n",
        "Q1 = merged_df[['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP']].quantile(0.25)\n",
        "Q3 = merged_df[['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP']].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Menghitung batas bawah dan atas untuk mendeteksi outliers\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Mendeteksi outliers\n",
        "outliers = (merged_df[['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP']] < lower_bound) | (merged_df[['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP']] > upper_bound)\n",
        "outlier_counts = outliers.sum()\n",
        "\n",
        "print(outlier_counts[outlier_counts > 0])  # Menampilkan jumlah outliers per kolom\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dtxhAPrkhPL"
      },
      "source": [
        "**Insight:**\n",
        "- Hasil analisis menunjukkan bahwa sejumlah besar kolom dalam dataset memiliki nilai yang hilang, dengan jumlah missing values tertinggi pada kolom CO (20,701), diikuti oleh O3 (13,277) dan NO2 (12,116). Ini menunjukkan bahwa data untuk polutan tertentu tidak lengkap, yang dapat memengaruhi akurasi analisis selanjutnya.\n",
        "- Analisis outliers mengungkapkan bahwa terdapat jumlah yang signifikan dari outliers di beberapa kolom polutan, dengan jumlah tertinggi pada kolom SO2 (35,566) dan CO (28,054). Keberadaan outliers ini dapat mengindikasikan kejadian polusi ekstrem atau kesalahan pengukuran yang perlu diteliti lebih lanjut.\n",
        "- Dari hasil assessing tersebut ada yang perlu ditangani dalam proses cleaning data selanjutnya, yaitu mengatasi missing value dan outliers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhN5R4hr8DC1"
      },
      "source": [
        "### Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jVnYpprE9Evz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data berhasil dibersihkan dan disimpan ke 'dashboard/cleaned_data.csv'\n"
          ]
        }
      ],
      "source": [
        "# Membaca data yang sudah digabungkan\n",
        "merged_df = pd.read_csv('dashboard/main_data.csv')\n",
        "\n",
        "# 1. Menangani Missing Values\n",
        "# Mengganti missing values dengan median untuk kolom numerik\n",
        "numeric_columns = ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']\n",
        "\n",
        "for column in numeric_columns:\n",
        "    median_value = merged_df[column].median()\n",
        "    merged_df[column] = merged_df[column].fillna(median_value)  # Tanpa inplace=True\n",
        "\n",
        "# Menangani missing values pada kolom non-numerik\n",
        "non_numeric_columns = ['wd']  # Tambahkan kolom non-numerik lainnya sesuai kebutuhan\n",
        "\n",
        "for column in non_numeric_columns:\n",
        "    mode_value = merged_df[column].mode()[0]  # Mendapatkan modus\n",
        "    merged_df[column] = merged_df[column].fillna(mode_value)  # Mengganti missing values dengan modus\n",
        "\n",
        "# 2. Menangani Outliers\n",
        "# Menggunakan metode IQR untuk mendeteksi outliers\n",
        "Q1 = merged_df[numeric_columns].quantile(0.25)\n",
        "Q3 = merged_df[numeric_columns].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Menghitung batas bawah dan atas untuk mendeteksi outliers\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Capping outliers\n",
        "for column in numeric_columns:\n",
        "    merged_df[column] = merged_df[column].clip(lower=lower_bound[column], upper=upper_bound[column])\n",
        "\n",
        "# 3. Validasi Data\n",
        "# Misalnya, memastikan nilai temperatur tidak lebih rendah dari -50\n",
        "merged_df['TEMP'] = merged_df['TEMP'].clip(lower=-50)\n",
        "\n",
        "# 4. Menghapus Duplikat\n",
        "merged_df.drop_duplicates(inplace=True)\n",
        "\n",
        "# 5. Menyimpan Data yang Sudah Dibersihkan\n",
        "merged_df.to_csv('dashboard/cleaned_data.csv', index=False)\n",
        "\n",
        "print(\"Data berhasil dibersihkan dan disimpan ke 'dashboard/cleaned_data.csv'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_5ejIqckiSP"
      },
      "source": [
        "**Insight:**\n",
        "- Proses pengisian nilai yang hilang (missing values) dengan menggunakan median untuk kolom numerik dan modus untuk kolom non-numerik (seperti arah angin) sangat membantu dalam menjaga integritas data. Dengan mengganti missing values, dapat memastikan bahwa analisis lebih akurat dan representatif terhadap kondisi nyata, sehingga hasil analisis tidak terdistorsi oleh nilai yang hilang.\n",
        "- Proses deteksi dan pengendalian outliers menggunakan metode IQR memberikan gambaran yang lebih bersih dan relevan tentang distribusi data kualitas udara. Capping outliers membantu mengurangi efek nilai ekstrem yang bisa mengganggu analisis dan interpretasi data kedepannya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp-Y6wU38DC1"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW7WF2kr8DC1"
      },
      "source": [
        "### Explore ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9CQCZjk8DC2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th_Lzl2Fkj9O"
      },
      "source": [
        "**Insight:**\n",
        "- xxx\n",
        "- xxx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsyZjqak8DC2"
      },
      "source": [
        "## Visualization & Explanatory Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZxOiQ6n8DC2"
      },
      "source": [
        "### Pertanyaan 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1swJUdAD8DC2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgHI7CiU8DC2"
      },
      "source": [
        "### Pertanyaan 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Go0lCsvO8DC2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0-36BDLklRg"
      },
      "source": [
        "**Insight:**\n",
        "- xxx\n",
        "- xxx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y4VUsmcYNZ5"
      },
      "source": [
        "## Analisis Lanjutan (Opsional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWhnzsJGYUCO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WeHlCeX8DC2"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTcyR48Y8DC2"
      },
      "source": [
        "- Conclution pertanyaan 1\n",
        "- Conclution pertanyaan 2"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "972b3bf27e332e87b5379f2791f6ef9dfc79c71018c370b0d7423235e20fe4d7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
